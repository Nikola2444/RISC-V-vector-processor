
assembly.o:     file format elf32-littleriscv


Disassembly of section .text:

00000000 <l_ch_batch_first_px-0x3c>:
   0:	00100f13          	li	t5,1
   4:	03100513          	li	a0,49
   8:	20000593          	li	a1,512
   c:	00001637          	lui	a2,0x1
  10:	80060613          	addi	a2,a2,-2048 # 800 <l_finished+0x6c0>
  14:	00400693          	li	a3,4
  18:	08000713          	li	a4,128
  1c:	40000a93          	li	s5,1024
  20:	00100b37          	lui	s6,0x100
  24:	00400bb7          	lui	s7,0x400
  28:	000a8333          	add	t1,s5,zero
  2c:	000b0133          	add	sp,s6,zero
  30:	000b81b3          	add	gp,s7,zero
  34:	000502b3          	add	t0,a0,zero
  38:	00267fd7          	vsetvli	t6,a2,e8,m4,tu,mu

0000003c <l_ch_batch_first_px>:
  3c:	00000013          	nop
  40:	000a8333          	add	t1,s5,zero
  44:	02030007          	vle8.v	v0,(t1)
  48:	97c06e57          	vmul.vx	v28,v28,zero
  4c:	97406a57          	vmul.vx	v20,v20,zero
  50:	02010207          	vle8.v	v4,(sp)
  54:	00c10133          	add	sp,sp,a2
  58:	96022c57          	vmul.vv	v24,v0,v4
  5c:	038e2e57          	vredsum.vs	v28,v24,v28
  60:	02010407          	vle8.v	v8,(sp)
  64:	00c10133          	add	sp,sp,a2
  68:	3bcf4a57          	vslideup.vx	v20,v28,t5
  6c:	03404e57          	vadd.vx	v28,v20,zero
  70:	96042c57          	vmul.vv	v24,v0,v8
  74:	038e2e57          	vredsum.vs	v28,v24,v28
  78:	02010607          	vle8.v	v12,(sp)
  7c:	00c10133          	add	sp,sp,a2
  80:	3bcf4a57          	vslideup.vx	v20,v28,t5
  84:	03404e57          	vadd.vx	v28,v20,zero
  88:	96062c57          	vmul.vv	v24,v0,v12
  8c:	038e2e57          	vredsum.vs	v28,v24,v28
  90:	02010807          	vle8.v	v16,(sp)
  94:	00c10133          	add	sp,sp,a2
  98:	3bcf4a57          	vslideup.vx	v20,v28,t5
  9c:	03404e57          	vadd.vx	v28,v20,zero
  a0:	96082c57          	vmul.vv	v24,v0,v16
  a4:	038e2e57          	vredsum.vs	v28,v24,v28
  a8:	0026ffd7          	vsetvli	t6,a3,e8,m4,tu,mu
  ac:	02018e27          	vse8.v	v28,(gp)
  b0:	fff28293          	addi	t0,t0,-1
  b4:	00b181b3          	add	gp,gp,a1
  b8:	00267fd7          	vsetvli	t6,a2,e8,m4,tu,mu

000000bc <l_ch_batch_other_px>:
  bc:	00000013          	nop
  c0:	00c30333          	add	t1,t1,a2
  c4:	02030007          	vle8.v	v0,(t1)
  c8:	97c06e57          	vmul.vx	v28,v28,zero
  cc:	97406a57          	vmul.vx	v20,v20,zero
  d0:	96022c57          	vmul.vv	v24,v0,v4
  d4:	038e2e57          	vredsum.vs	v28,v24,v28
  d8:	96042c57          	vmul.vv	v24,v0,v8
  dc:	3bcf4a57          	vslideup.vx	v20,v28,t5
  e0:	03404e57          	vadd.vx	v28,v20,zero
  e4:	038e2e57          	vredsum.vs	v28,v24,v28
  e8:	96062c57          	vmul.vv	v24,v0,v12
  ec:	3bcf4a57          	vslideup.vx	v20,v28,t5
  f0:	03404e57          	vadd.vx	v28,v20,zero
  f4:	038e2e57          	vredsum.vs	v28,v24,v28
  f8:	96082c57          	vmul.vv	v24,v0,v16
  fc:	3bcf4a57          	vslideup.vx	v20,v28,t5
 100:	03404e57          	vadd.vx	v28,v20,zero
 104:	038e2e57          	vredsum.vs	v28,v24,v28
 108:	0026ffd7          	vsetvli	t6,a3,e8,m4,tu,mu
 10c:	02018e27          	vse8.v	v28,(gp)
 110:	00b181b3          	add	gp,gp,a1
 114:	00267fd7          	vsetvli	t6,a2,e8,m4,tu,mu
 118:	fff28293          	addi	t0,t0,-1
 11c:	00028463          	beqz	t0,124 <l_ch_batch_exit>
 120:	f9dff0ef          	jal	ra,bc <l_ch_batch_other_px>

00000124 <l_ch_batch_exit>:
 124:	00000013          	nop
 128:	fff70713          	addi	a4,a4,-1
 12c:	000502b3          	add	t0,a0,zero
 130:	00db8bb3          	add	s7,s7,a3
 134:	000b81b3          	add	gp,s7,zero
 138:	00070463          	beqz	a4,140 <l_finished>
 13c:	f01ff0ef          	jal	ra,3c <l_ch_batch_first_px>

00000140 <l_finished>:
 140:	00000013          	nop
 144:	00000013          	nop
 148:	00000013          	nop
 14c:	00000013          	nop
 150:	00000013          	nop
